# Complete Call Flow Analysis - All Types with Translation

**Date:** January 12, 2026  
**Purpose:** Visual representation of all call flows + gap analysis  
**Status:** ğŸš¨ **CRITICAL GAPS IDENTIFIED**

---

## ğŸ¯ **EXECUTIVE SUMMARY**

**What You Asked For:** Live caller-to-caller translation using ElevenLabs  
**What I Implemented:** Post-call translation audio generation  
**Gap:** Real-time translation NOT implemented  
**Required:** SignalWire AI Agent integration + ElevenLabs streaming

---

## ğŸ“Š **CALL FLOW TYPE 1: SINGLE-LEG CALL (No Translation)**

### **Current Implementation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SINGLE-LEG CALL FLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER (UI)
  â”‚
  â”‚ 1. Start Call (phone_number)
  â”œâ”€â”€> startCallHandler.ts
  â”‚      â”‚
  â”‚      â”‚ 2. Create call record
  â”‚      â”œâ”€â”€> Supabase: INSERT calls
  â”‚      â”‚
  â”‚      â”‚ 3. Initiate SignalWire call
  â”‚      â”œâ”€â”€> SignalWire REST API
  â”‚      â”‚      - From: +1234567890
  â”‚      â”‚      - To: customer_number
  â”‚      â”‚      - Record: true âœ…
  â”‚      â”‚      - Url: /api/voice/laml/outbound?callId=xxx
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns call_sid
  â”‚
SignalWire (Media Plane)
  â”‚
  â”‚ 4. Fetch LaML instructions
  â”œâ”€â”€> GET /api/voice/laml/outbound
  â”‚      â””â”€â”€> Returns:
  â”‚             <Response>
  â”‚               <Pause length="3600"/>  â† Keeps call alive
  â”‚               <Hangup/>
  â”‚             </Response>
  â”‚
  â”‚ 5. Call executes (audio flows)
  â”‚    RTP â†â”€â”€â†’ Customer
  â”‚
  â”‚ 6. Call ends
  â”œâ”€â”€> SignalWire records audio
  â”‚
  â”‚ 7. POST webhook (call completed + recording)
  â”œâ”€â”€> POST /api/webhooks/signalwire
  â”‚      â”‚
  â”‚      â”‚ 8. Save recording URL
  â”‚      â”œâ”€â”€> Supabase: UPDATE calls (status = completed)
  â”‚      â”‚
  â”‚      â”‚ 9. Queue transcription
  â”‚      â”œâ”€â”€> AssemblyAI: Submit audio for transcription
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns 200 OK
  â”‚
AssemblyAI (Intelligence Plane)
  â”‚
  â”‚ 10. Transcription complete
  â”œâ”€â”€> POST /api/webhooks/assemblyai
  â”‚      â”‚
  â”‚      â”‚ 11. Save transcript
  â”‚      â”œâ”€â”€> Supabase: INSERT ai_runs (model = 'transcription')
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns 200 OK
  â”‚
Database (Supabase)
  â”‚
  â””â”€â”€> calls: status = completed âœ…
       recordings: transcript_json populated âœ…
       ai_runs: transcription completed âœ…
```

**Status:** âœ… **WORKING** (as of fix on Jan 12, 2026)

---

## ğŸ“Š **CALL FLOW TYPE 2: BRIDGE CALL (Two-Legged, No Translation)**

### **Current Implementation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BRIDGE CALL FLOW (Two-Legged)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER (UI)
  â”‚
  â”‚ 1. Start Bridge Call
  â”œâ”€â”€> startCallHandler.ts
  â”‚      â”‚
  â”‚      â”‚ 2. Create call record
  â”‚      â”œâ”€â”€> Supabase: INSERT calls
  â”‚      â”‚
  â”‚      â”‚ 3. Create conference name
  â”‚      â”‚    conference = `bridge-${callId}`
  â”‚      â”‚
  â”‚      â”‚ 4. Initiate LEG A (from_number)
  â”‚      â”œâ”€â”€> SignalWire REST API (Leg A)
  â”‚      â”‚      - From: company_number
  â”‚      â”‚      - To: from_number (Party A)
  â”‚      â”‚      - Url: /api/voice/laml/outbound?
  â”‚      â”‚              callId=xxx&
  â”‚      â”‚              conference=bridge-xxx&
  â”‚      â”‚              leg=1
  â”‚      â”‚
  â”‚      â”‚ 5. Initiate LEG B (to_number)
  â”‚      â”œâ”€â”€> SignalWire REST API (Leg B)
  â”‚      â”‚      - From: company_number
  â”‚      â”‚      - To: to_number (Party B)
  â”‚      â”‚      - Url: /api/voice/laml/outbound?
  â”‚      â”‚              callId=xxx&
  â”‚      â”‚              conference=bridge-xxx&
  â”‚      â”‚              leg=2
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns call_sids for both legs
  â”‚
SignalWire (Media Plane - LEG A)
  â”‚
  â”‚ 6a. Fetch LaML for Leg A
  â”œâ”€â”€> GET /api/voice/laml/outbound?conference=bridge-xxx&leg=1
  â”‚      â””â”€â”€> Returns:
  â”‚             <Response>
  â”‚               <Dial>
  â”‚                 <Conference record="record-from-answer"
  â”‚                             recordingStatusCallback="/api/webhooks/signalwire"
  â”‚                             recordingStatusCallbackEvent="completed">
  â”‚                   bridge-xxx
  â”‚                 </Conference>
  â”‚               </Dial>
  â”‚             </Response>
  â”‚
SignalWire (Media Plane - LEG B)
  â”‚
  â”‚ 6b. Fetch LaML for Leg B
  â”œâ”€â”€> GET /api/voice/laml/outbound?conference=bridge-xxx&leg=2
  â”‚      â””â”€â”€> Returns: (same LaML as Leg A)
  â”‚
  â”‚ 7. Both legs join conference
  â”‚    Party A â†â”€â”€â”€â”€â”€â”€â†’ Conference â†â”€â”€â”€â”€â”€â”€â†’ Party B
  â”‚                      â”‚
  â”‚                      â””â”€â”€> SignalWire mixes audio
  â”‚
  â”‚ 8. Conference records audio
  â”‚    (Only ONE recording, not two!)
  â”‚
  â”‚ 9. Call ends
  â”œâ”€â”€> POST webhook (conference recording)
  â”œâ”€â”€> POST /api/webhooks/signalwire
  â”‚      â”‚
  â”‚      â”‚ 10. Save recording + queue transcription
  â”‚      â””â”€â”€> (same flow as single-leg)
  â”‚
Database (Supabase)
  â””â”€â”€> calls: status = completed âœ…
       recordings: ONE recording for both legs âœ…
```

**Status:** âœ… **WORKING** (as of fix on Jan 12, 2026)

---

## ğŸ“Š **CALL FLOW TYPE 3: POST-CALL TRANSLATION** 

### **Current Implementation (What I Just Added):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              POST-CALL TRANSLATION WITH AUDIO                    â”‚
â”‚              (ElevenLabs - AFTER call ends)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[... Call completes normally (Type 1 or 2) ...]
  â”‚
AssemblyAI Webhook
  â”‚
  â”‚ 1. Transcription complete
  â”œâ”€â”€> POST /api/webhooks/assemblyai
  â”‚      â”‚
  â”‚      â”‚ 2. Save transcript
  â”‚      â”œâ”€â”€> Supabase: ai_runs (model = 'transcription')
  â”‚      â”‚      â””â”€â”€> transcript_json = {"text": "Hola, Â¿cÃ³mo estÃ¡s?"}
  â”‚      â”‚
  â”‚      â”‚ 3. Check if translation enabled
  â”‚      â”œâ”€â”€> voice_configs.translate === true?
  â”‚      â”‚      â”‚
  â”‚      â”‚      â””â”€â”€> YES
  â”‚      â”‚
  â”‚      â”‚ 4. Create translation job
  â”‚      â”œâ”€â”€> Supabase: ai_runs (model = 'translation', status = 'pending')
  â”‚      â”‚
  â”‚      â”‚ 5. Queue translation
  â”‚      â””â”€â”€> Call translation.translateText()
  â”‚
Translation Service (app/services/translation.ts)
  â”‚
  â”‚ 6. Translate text
  â”œâ”€â”€> OpenAI API: "Translate: Hola, Â¿cÃ³mo estÃ¡s?"
  â”‚      â””â”€â”€> Returns: "Hello, how are you?"
  â”‚
  â”‚ 7. Generate audio âœ¨ NEW!
  â”œâ”€â”€> ElevenLabs API: generateSpeech("Hello, how are you?", "en")
  â”‚      â””â”€â”€> Returns: audio stream (MP3)
  â”‚
  â”‚ 8. Upload audio to storage
  â”œâ”€â”€> Supabase Storage: upload('translations/xxx.mp3', audioBuffer)
  â”‚      â””â”€â”€> Returns: public URL
  â”‚
  â”‚ 9. Update translation record
  â”œâ”€â”€> Supabase: UPDATE ai_runs
  â”‚      output = {
  â”‚        translated_text: "Hello, how are you?",
  â”‚        translated_audio_url: "https://...mp3", â† NEW!
  â”‚        tts_provider: "elevenlabs"               â† NEW!
  â”‚      }
  â”‚
UI (components/voice/TranslationView.tsx)
  â”‚
  â”‚ 10. Display translation
  â””â”€â”€> Shows:
         - Original text: "Hola, Â¿cÃ³mo estÃ¡s?"
         - Translated text: "Hello, how are you?"
         - ğŸ”Š Audio player â† NEW!
```

**Status:** âœ… **WORKING** (just implemented)  
**But:** This is POST-CALL, not LIVE translation!

---

## ğŸ“Š **CALL FLOW TYPE 4: LIVE TRANSLATION (SignalWire AI Agent)**

### **REQUIRED BUT NOT IMPLEMENTED:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LIVE TRANSLATION (Real-Time, Caller-to-Caller)         â”‚
â”‚           SignalWire AI Agent + ElevenLabs TTS                   â”‚
â”‚           ğŸš¨ NOT YET IMPLEMENTED ğŸš¨                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER (UI)
  â”‚
  â”‚ 1. Start Call with LIVE translation
  â”œâ”€â”€> startCallHandler.ts
  â”‚      â”‚
  â”‚      â”‚ 2. Check capabilities
  â”‚      â”œâ”€â”€> /api/call-capabilities
  â”‚      â”‚      â””â”€â”€> real_time_translation_preview: true?
  â”‚      â”‚           (requires Business plan + feature flag)
  â”‚      â”‚
  â”‚      â”‚ 3. Get language settings
  â”‚      â”œâ”€â”€> voice_configs
  â”‚      â”‚      - translation_from: "es" (Spanish)
  â”‚      â”‚      - translation_to: "en" (English)
  â”‚      â”‚
  â”‚      â”‚ 4. Build AI Agent config
  â”‚      â”œâ”€â”€> signalwire/agentConfig.ts
  â”‚      â”‚      â””â”€â”€> Returns SWML JSON with:
  â”‚      â”‚           - Language detection
  â”‚      â”‚           - Translation prompts
  â”‚      â”‚           - TTS voices
  â”‚      â”‚
  â”‚      â”‚ 5. Initiate call with AI Agent
  â”‚      â”œâ”€â”€> SignalWire REST API
  â”‚      â”‚      - From: +1234567890
  â”‚      â”‚      - To: customer_number
  â”‚      â”‚      - Url: /api/voice/swml/outbound?callId=xxx
  â”‚      â”‚      - AI_AGENT_CONFIG: {...} â† NEW!
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns call_sid
  â”‚
SignalWire AI Agent (Media Plane + Intelligence)
  â”‚
  â”‚ 6. Fetch SWML instructions
  â”œâ”€â”€> GET /api/voice/swml/outbound
  â”‚      â””â”€â”€> Returns SWML JSON:
  â”‚           {
  â”‚             "sections": {
  â”‚               "main": [
  â”‚                 {"answer": {}},
  â”‚                 {"ai": {
  â”‚                   "prompt": {
  â”‚                     "text": "Real-time translator: es â†’ en"
  â”‚                   },
  â”‚                   "post_prompt": {
  â”‚                     "temperature": 0.3,
  â”‚                     "top_p": 0.8
  â”‚                   },
  â”‚                   "languages": ["es-MX", "en-US"],
  â”‚                   "params": {
  â”‚                     "record_call": true,
  â”‚                     "engine": "gpt-4o-mini"
  â”‚                   }
  â”‚                 }}
  â”‚               ]
  â”‚             }
  â”‚           }
  â”‚
  â”‚ 7. AI Agent activates
  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    â”‚  SignalWire AI Agent Pipeline:       â”‚
  â”‚    â”‚                                       â”‚
  â”‚    â”‚  Customer speaks (Spanish)            â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  [STT] â†’ "Hola, Â¿cÃ³mo estÃ¡s?"       â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  [Language Detection] â†’ Spanish      â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  [LLM Translation] â†’ GPT-4o-mini     â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  "Hello, how are you?"               â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  [TTS] â†’ SignalWire's built-in TTS   â”‚
  â”‚    â”‚      â†“                                â”‚
  â”‚    â”‚  [Audio Injection] â†’ Play to agent   â”‚
  â”‚    â”‚                                       â”‚
  â”‚    â”‚  (Reverse flow for agent â†’ customer) â”‚
  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”‚ 8. Real-time audio flow
  â”‚    Customer (Spanish) â”€â”€â”€â”€â”€â”
  â”‚                             â”œâ”€â”€> AI Agent â”€â”€> Agent (English)
  â”‚    Customer (hears English) â†â”€â”€â”€ AI Agent â†â”€â”€ Agent (Spanish)
  â”‚
  â”‚ 9. Call recording (with translations)
  â”‚    SignalWire records mixed audio
  â”‚
  â”‚ 10. Call ends
  â”œâ”€â”€> POST webhook
  â”œâ”€â”€> POST /api/webhooks/signalwire
  â”‚      â”‚
  â”‚      â”‚ 11. Mark as live translation
  â”‚      â”œâ”€â”€> Supabase: UPDATE recordings
  â”‚      â”‚      - has_live_translation = true
  â”‚      â”‚      - live_translation_provider = 'signalwire'
  â”‚      â”‚
  â”‚      â”‚ 12. Queue CANONICAL transcription
  â”‚      â”œâ”€â”€> AssemblyAI (AUTHORITATIVE source)
  â”‚      â”‚
  â”‚      â””â”€â”€> Returns 200 OK
  â”‚
AssemblyAI (Canonical Source)
  â”‚
  â”‚ 13. Post-call transcription + translation
  â”œâ”€â”€> (Same as Type 3 - POST-CALL flow)
  â”‚
  â””â”€â”€> ai_runs: AUTHORITATIVE transcript
       (SignalWire AI output is ephemeral, non-authoritative)
```

**Status:** ğŸš¨ **NOT IMPLEMENTED**  
**Priority:** HIGH if you want live translation

---

## ğŸ“Š **CALL FLOW TYPE 5: LIVE TRANSLATION with ELEVENLABS**

### **IDEAL IMPLEMENTATION (What You're Asking For):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LIVE TRANSLATION - ENHANCED WITH ELEVENLABS TTS              â”‚
â”‚     (Best Quality - Not Yet Implemented)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[... Same as Type 4, but replace SignalWire TTS with ElevenLabs ...]

SignalWire AI Agent Pipeline (Modified):
  â”‚
  Customer speaks (Spanish)
      â†“
  [STT] â†’ "Hola, Â¿cÃ³mo estÃ¡s?"
      â†“
  [Language Detection] â†’ Spanish
      â†“
  [LLM Translation] â†’ GPT-4o-mini
      â†“
  "Hello, how are you?"
      â†“
  [ElevenLabs TTS] â† âœ¨ REPLACE SignalWire TTS!
      - Better voice quality
      - More natural prosody
      - Voice cloning possible
      â†“
  [Stream to SignalWire Media Streams]
      â†“
  [Audio Injection] â†’ Play to agent

**Implementation Requirements:**
1. SignalWire AI Agent for STT + Translation
2. ElevenLabs Streaming API for TTS
3. SignalWire Media Streams for audio injection
4. WebSocket handling for real-time streaming
```

**Status:** ğŸš¨ **NOT IMPLEMENTED**  
**Complexity:** â­â­â­â­â˜† (Advanced)  
**Timeline:** 1-2 weeks

---

## ğŸ” **LANGUAGE DETECTION LOGIC**

### **Current Implementation:**

```typescript
// In voice_configs table:
{
  translation_from: "es",  // Source language
  translation_to: "en",    // Target language
  translate: true          // Enable translation
}

// Language detection happens in:
// 1. AssemblyAI (automatic language detection)
// 2. SignalWire AI Agent (if configured - NOT IMPLEMENTED)
// 3. Manual selection by user (voice_configs)
```

### **For Live Translation (Required):**

```typescript
// In signalwire/agentConfig.ts (NOT YET CREATED):
function buildAgentConfig(params: {
  callId: string
  organizationId: string
  translationFrom: string  // From voice_configs
  translationTo: string    // From voice_configs
}): SignalWireAgentConfig {
  return {
    agent: {
      languages: {
        primary: params.translationFrom || "auto",  // Auto-detect if not specified
        target: params.translationTo
      },
      prompt: {
        system: `You are a real-time translator. 
                 Detect the speaker's language automatically.
                 Translate from ${params.translationFrom} to ${params.translationTo}.
                 Preserve tone and intent.`
      },
      // ...
    }
  }
}
```

**Language Detection Flow:**
```
1. User selects languages in Settings â†’ voice_configs
2. Call starts â†’ Agent receives language config
3. First speech detected â†’ AI Agent detects actual language
4. If detected â‰  configured â†’ Use detected language
5. Translate in real-time
```

---

## ğŸš¨ **CRITICAL GAPS IDENTIFIED**

### **Gap #1: No Live Translation Implementation**
**What's Missing:**
- âœ… Post-call translation with audio (just added)
- âŒ Real-time translation during calls
- âŒ SignalWire AI Agent integration
- âŒ SWML endpoint working correctly
- âŒ Language detection in real-time

**Impact:** Users CANNOT translate calls in real-time

---

### **Gap #2: ElevenLabs for Post-Call Only**
**What Was Implemented:**
- âœ… ElevenLabs generates audio AFTER call ends
- âœ… Audio stored and played in UI

**What's Missing:**
- âŒ ElevenLabs streaming during live calls
- âŒ Integration with SignalWire Media Streams
- âŒ Real-time audio injection

**Impact:** High-quality voice only available post-call

---

### **Gap #3: Incomplete SWML Implementation**
**Files Exist:**
- âœ… `app/api/voice/swml/outbound/route.ts` (exists)
- âœ… `lib/signalwire/swmlBuilder.ts` (exists)

**Problems:**
- âŒ Not tested with live translation
- âŒ AI Agent config not dynamic (hard-coded)
- âŒ No language parameter passing
- âŒ No capability gating

**Impact:** Live translation route exists but may not work

---

### **Gap #4: No Capability Gating**
**Required (per architecture):**
- Business plan + feature flag
- `TRANSLATION_LIVE_ASSIST_PREVIEW` env var
- Capability API returns `real_time_translation_preview`

**Current Status:**
- âŒ Feature flag exists but not checked in call flow
- âŒ Capability API doesn't return live translation capability
- âŒ UI doesn't show live translation toggle

**Impact:** Can't control who gets live translation

---

### **Gap #5: No Language Detection in Live Calls**
**Required:**
- Auto-detect caller's language
- Switch languages mid-call
- Fall back to configured language

**Current Status:**
- âŒ No detection logic in AI Agent
- âŒ Languages hard-coded or missing
- âŒ No fallback strategy

**Impact:** Wrong language translation

---

## ğŸ“‹ **ISSUES LIST**

### **Issue #1: Wrong Feature Implemented**
**Severity:** ğŸ”´ **CRITICAL**  
**Description:** Implemented POST-call audio instead of LIVE translation  
**Fix Required:** Implement SignalWire AI Agent integration  
**Timeline:** 2-3 days  
**Files Affected:**
- `app/actions/calls/startCallHandler.ts` (add AI Agent logic)
- `lib/signalwire/agentConfig.ts` (create)
- `app/api/voice/swml/outbound/route.ts` (fix)

---

### **Issue #2: SWML Route Untested**
**Severity:** ğŸŸ¡ **HIGH**  
**Description:** SWML endpoint exists but not verified for live translation  
**Fix Required:** Test and fix SWML generation  
**Timeline:** 1 day  
**Files Affected:**
- `app/api/voice/swml/outbound/route.ts`
- `lib/signalwire/swmlBuilder.ts`

---

### **Issue #3: Missing Capability Gating**
**Severity:** ğŸŸ¡ **HIGH**  
**Description:** No Business plan + feature flag check for live translation  
**Fix Required:** Add capability checks  
**Timeline:** 4 hours  
**Files Affected:**
- `app/api/call-capabilities/route.ts`
- `components/voice/CallModulations.tsx`
- `lib/rbac.ts`

---

### **Issue #4: ElevenLabs Not Used in Live Calls**
**Severity:** ğŸŸ  **MEDIUM**  
**Description:** ElevenLabs only used post-call, not during calls  
**Fix Required:** Implement ElevenLabs streaming API + Media Streams  
**Timeline:** 1-2 weeks  
**Files Affected:**
- `app/services/elevenlabs.ts` (add streaming)
- New file: `app/services/realtimeTranslation.ts`

---

### **Issue #5: No Language Auto-Detection**
**Severity:** ğŸŸ  **MEDIUM**  
**Description:** Languages must be pre-configured, no auto-detection  
**Fix Required:** Add detection logic to AI Agent config  
**Timeline:** 4 hours  
**Files Affected:**
- `lib/signalwire/agentConfig.ts`

---

### **Issue #6: Missing Schema Fields**
**Severity:** ğŸŸ¢ **LOW**  
**Description:** Need `has_live_translation` in recordings table  
**Fix Required:** Run migration  
**Timeline:** 30 minutes  
**Files Affected:**
- New file: `migrations/2026-01-12-add-live-translation-fields.sql`

---

## âœ… **WHAT WORKS NOW**

1. âœ… **Single-leg calls** - Record + transcribe
2. âœ… **Bridge calls** - Two parties in conference
3. âœ… **Post-call translation** - Text translation via OpenAI
4. âœ… **Post-call audio** - ElevenLabs generates audio (NEW!)
5. âœ… **Audio playback** - UI plays translated audio (NEW!)
6. âœ… **Recording** - SignalWire records all calls

---

## ğŸš¨ **WHAT DOESN'T WORK**

1. âŒ **Live translation** - Real-time translation during calls
2. âŒ **Caller-to-caller translation** - A speaks Spanish, B hears English
3. âŒ **Language auto-detection** - In real-time
4. âŒ **ElevenLabs live streaming** - High-quality voice during calls
5. âŒ **Capability gating** - Business plan restriction

---

## ğŸ¯ **RECOMMENDED FIX PRIORITY**

### **Phase 1: Implement Live Translation (1 week)**
1. Create SignalWire AI Agent config builder
2. Fix SWML endpoint for live translation
3. Add capability gating
4. Test with manual languages
5. Deploy and test

### **Phase 2: Add ElevenLabs Live Streaming (2 weeks)**
1. Implement ElevenLabs streaming API
2. Integrate with SignalWire Media Streams
3. WebSocket handling
4. Test quality and latency

### **Phase 3: Language Auto-Detection (3 days)**
1. Add detection to AI Agent
2. Fallback logic
3. UI indicators

---

## ğŸ“ **NEXT STEPS**

**Immediate (Today):**
1. Review this document
2. Confirm you want LIVE translation (not just post-call audio)
3. Decide on priority: SignalWire TTS (fast) vs ElevenLabs streaming (quality)

**Then:**
1. I'll implement SignalWire AI Agent integration
2. Fix SWML endpoint
3. Add capability gating
4. Test live translation

**Want me to start?** ğŸš€
